---
title: "面向辅助驾驶应用的鱼眼相机环视拼接方案"
collection: projects
type: "Project"
permalink: /projects/2021-10-13-avm
venue: "CICV"
date: 2021-10-13
location: "Beijing, China"
---

面向辅助驾驶应用的鱼眼相机环视拼接方案

## 1.环视图像拼接(AVM)意义及目标

在自动驾驶或者自主泊车系统中，环视全景图像拼接可以消除车辆周围的视觉盲点，帮助驾驶员更加直观地确认周围路况。在本项目中，需要在环视全景图像中完成地面标线的语义分割，用于后续建图和定位。本方案基于车体四周安装的四个180&deg;鱼眼相机，完成环视图像拼接。

## 2.AVM算法原理

### 2.0 鱼眼图像校正

根据鱼眼相机内参标定结果，对鱼眼相机图像进行校正，如图2.1.1所示。

![result_screenshot_18.09.2021](https://sunqinxuan.github.io/images/projects-2021-10-13-img1.png)

图2.1.1 鱼眼图像校正: (左)校正前 (右)校正后

### 2.1 俯视变换

经过相机-车体外参标定，可以得到右、前、左、后四个环视相机的相对于车体后轮中心的位姿分别为\\(T_{wc_1}\\)、\\(T_{wc_2}\\)、\\(T_{wc_3}\\)和\\(T_{wc_4}\\)。已知IMU安装在车体后轴中心，假设车体后轮间距为$d$，后轴高度为$h$，则可知车体左后轮坐标系到IMU坐标系(即为车体坐标系)的变换为

$$
T_{vw}=
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & d/2 \\
0 & 0 & 1 & -h \\
0 & 0 & 0 & 1
\end{bmatrix}
$$

假设地面上一点\\(p\\)在车体坐标系下的坐标为\\(p_{v}\\)，对应齐次坐标为\\(\tilde{p}_{v}\\)，以右视相机为例，该点在相机坐标系下的齐次坐标\\(\tilde{p}_{c1}\\)可以计算为

$$
\tilde{p}_{c1}=T_{wc_1}^{-1}T_{vw}^{-1}\tilde{p}_v
$$

通过相机内参标定获得的相机内参矩阵\\(K\\)和畸变模型参数\\(D\\)，根据鱼眼相机模型，可以得到\\(p_{c1}\\)对应鱼眼图像的像素坐标\\((u_{c1},v_{c1})^T\\)。


### 2.2 环视图像生成

车体周围生成环视图像的区域大小为\\(L\times L\\)，将此区域栅格化成为\\(N\times N\\)的单元格，每一个单元格对应环视图像的一个像素，则每个像素的物理尺寸为\\({L}/{N}\\)。假设车体坐标系原点在地面上的垂直投影点对应的环视图像像素坐标为\\((c_x,c_y)^T\\)，则对于任一像素点\\((u,v)^T\\)，其对应地面点在车体坐标系下的3D坐标\\(p_v\\)为

$$
p_v=
\begin{bmatrix}
(c_x-u)\frac{L}{N} \\
(c_y-v)\frac{L}{N} \\
-h
\end{bmatrix}
$$

根据2.2节内容，可以直接得到$p_v$对应的图像平面像素坐标\\((u_{c},v_{c})^T\\)，对该像素坐标分别进行上下取整，可以得到四个离散坐标值，分别记为\\((u_{c\_floor},v_{c\_floor})^T\\)、\\((u_{c\_floor},v_{c\_ceil})^T\\)、\\((u_{c\_ceil},v_{c\_floor})^T\\)和\\((u_{c\_ceil},v_{c\_ceil})^T\\)，进行双线性插值可得

$$
f(u_c,v_{c\_floor})=
\frac{u_{c\_ceil}-u_c}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_floor},v_{c\_floor})
+\frac{u_c-u_{c\_floor}}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_ceil},v_{c\_floor}) 
$$

$$
f(u_c,v_{c\_ceil})=
\frac{u_{c\_ceil}-u_c}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_floor},v_{c\_ceil})
+\frac{u_c-u_{c\_floor}}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_ceil},v_{c\_ceil}) 
$$

$$
f(u_c,v_c)=
\frac{v_{c\_ceil}-v_c}{v_{c\_ceil}-v_{c\_floor}}
f(u_{c},v_{c\_floor})
+\frac{v_c-v_{c\_floor}}{v_{c\_ceil}-v_{c\_floor}}
f(u_{c},v_{c\_ceil}) 
$$

其中，\\(f(u_c,v_c)\\)表示像素坐标\\((u_{c},v_{c})^T\\)处的图像颜色值。至此得到环视图像\\((u,v)^T\\)坐标处的颜色值，即完成环视图像的生成。

$$
f_{AVM}(u,v)=f(u_c,v_c)
$$


### 2.3 视野重叠区域处理

对于安装在车体四周的180&deg;鱼眼相机，两两之间存在视野重叠区域，如图2.3.1所示，I、III、VI和VIII四个区域内的点，可能同时被相邻的两个相机观测到，对于这些点，需要进行额外的融合处理。

<img src="https://sunqinxuan.github.io/images/projects-2021-10-13-img2.png" alt="Screenshot from 2021-09-22 09-30-14" style="zoom:50%;" />

图2.3.1 车体四周区域划分

不失一般性，以区域III为例，假设其中一点\\((u,v)^T\\)可以被右视相机和前视相机同时观测到，其对应右视相机和前视相机图像上的像素坐标分别为\\((u_{c1},v_{c1})^T\\)和\\((u_{c2},v_{c2})^T\\)。另外，假设右视和前视相机图像平面中心点分别为\\((c_{x1},c_{y1})^T\\)和\\((c_{x2},c_{y2})^T\\)，令

$$
\rho_1=\sqrt{(u_{c1}-c_{x1})^2+(v_{c1}-c_{y1})^2} 
$$

$$
\rho_2=\sqrt{(u_{c2}-c_{x2})^2+(v_{c2}-c_{y2})^2}
$$

基于越靠近图像边缘的点，畸变越大的原则，设计视野重叠区域融合方案为

$$
f_{AVM}(u,v)=
\frac{1}{\rho_1}f_{c1}(u_{c1},v_{c1})
+\frac{1}{\rho_2}f_{c2}(u_{c2},v_{c2})
$$

## 3.AVM系统实现方案

### 3.1 AVM算法流程

图3.1.1为AVM算法总体流程，其输入为鱼眼相机图像、相机内外参以及给定AVM生成范围，输出为AVM环视图像，处理过程主要包含逆向投影变换、双线性插值和视野重合区域融合。

```mermaid
graph LR
input_img(鱼眼相机图像)
input_cam(相机内外参)
output(AVM图像)
AVMcoords(AVM生成范围)
AVM2vehicle[逆向投影变换]
bilinear_interp[双线性插值]
overlap[视野重合区域融合]

AVMcoords --> AVM2vehicle 
input_cam --> AVM2vehicle 
AVM2vehicle --> bilinear_interp
input_img --> bilinear_interp
bilinear_interp --> overlap
overlap --> output
```

图3.1.1 AVM算法流程

逆向投影变换主要将AVM环视图像中的各个像素点对应的地面点3D坐标变换到环视相机图像平面坐标系，将得到的像素坐标离散化后可以获取对应的图像颜色值。接着，通过双线性插值算法，计算得到对应AVM图像坐标处的颜色值。最后，对相邻相机的视野重合区域的像素点进行融合，得到AVM图像结果。

### 3.2 AVM类结构设计

```mermaid
classDiagram
	AVM <-- AVMFlow
	class AVMFlow {
	-avm_ptr_;
	-camera_info_sub_ptr;
	-image_sub_ptr;
	-avm_image_pub_ptr_;
	+ReadData();
	+HasData();
	+ValidData();
	+RunData();
	+PublishData();
	}
	class AVM {
	-trans_vehicle_wheel_;
	+Run();
	-InverseProjection();
	-BilinearInterp();
	-OverlapFusion();
	}
```

#### 3.2.1 AVMFlow类

AVMFlow类是适配ROS接口的AVM拼接数据流类，包含对环视相机图像数据以及相机内外参数据的读取、存在状态判断、有效状态判断、数据处理以及AVM拼接图像数据的发布。该类的主要方法有：

```c++
bool ReadData(); // 从ROS的消息队列中读取数据，成功返回true;
bool HasData(); // 判断当前时刻所需数据队列是否非空，非空返回true;
bool ValidData(); // 判断最新数据是否有效，有效返回true;
bool RunData(); // 执行AVM图像拼接，成功返回true;
bool PublishData(); // 发布AVM图像数据，成功返回true;
```

该类的主要成员变量有：

```c++
avm_ptr_; // AVM图像拼接核心处理类对象指针;
camera_info_sub_ptr_; // 相机内外参数据接收指针;
image_sub_ptr_; // 环视相机图像数据接收指针;
avm_image_pub_ptr_; // AVM图像数据发布指针;
```

#### 3.2.2 AVM类

AVM类是AVM图像拼接核心处理类，包含对给定AVM图像观测地面范围进行逆向投影、环视图像颜色值的双线性插值以及对相邻相机视野重合区域的融合处理。该类的主要方法有：

```c++
bool Run(); // 核心函数对外接口;
bool InverseProjection(); // 逆向投影功能函数;
bool BilinearInterp(); // 双线性插值函数;
bool OverlapFusion(); // 视野重合区域融合函数;
```

该类的主要成员变量有：

```c++
trans_vehicle_wheel_; // 标定布十字交叉处坐标系到车体坐标系的变换;
```

## 4.自适应IPM算法

### 4.1 算法原理

使用标定好的相机-车体外参生成AVM图像时，需要满足车体坐标系OXY平面与地面保持平行，但是在车辆加减速以及经过减速带时，无法保持车体与地面的平行。因此，使用组合导航给出的车体俯仰角以及横滚角的观测值，在自适应IPM算法过程中对车体的姿态进行补偿。

在自适应IPM算法中，假设组合导航系统提供的车体俯仰角和横滚角分别为\\(\theta\\)和\\(\varphi\\)，根据车体坐标系的设置，可知须补偿的车体旋转变换为

$$
R_{adapt}=
R_{x,-\varphi}R_{y,-\theta}=
\begin{bmatrix}
1 & 0 & 0 \\
0 & \cos(-\varphi) & \sin(-\varphi) \\
0 & -\sin(-\varphi) & \cos(-\varphi) \\
\end{bmatrix}
\begin{bmatrix}
\cos(-\varphi) & 0 & -\sin(-\varphi) \\
0 & 1 & 0 \\
\sin(-\varphi) & 0 & \cos(-\varphi) \\
\end{bmatrix}
$$

补偿后，车体坐标系到车体后轮（即标定布）坐标系变换为

$$
T_{wv}'=T_{wv}\cdot
\begin{bmatrix}
R_{adapt} & \boldsymbol 0 \\
\boldsymbol 0^T & 1 
\end{bmatrix}
$$

### 4.2 调试记录

在通过停车场不同区域之间的连接处时，由于坡度较大，可以直观看出补偿效果，如图4.2.1所示。

<img src="https://sunqinxuan.github.io/images/projects-2021-10-13-img3.png" style="zoom:70%;" />

<img src="https://sunqinxuan.github.io/images/projects-2021-10-13-img4.png" alt="Screenshot from 2021-10-08 15-26-55" style="zoom:70%;" />

图4.2.1 地下停车场自适应IPM算法补偿效果：(左)补偿前，(右)补偿后

在车辆通过减速带时，难以直观看出补偿效果。输出俯仰角变化曲线如图4.2.2所示，前后三个较大的尖峰对应出入停车场的上下坡过程，而中间四个脉冲对应停车场区域之间连接处，除此外，不存在特定波型与减速带产生明确的对应关系。

![image-2](https://sunqinxuan.github.io/images/projects-2021-10-13-img5.png)

图4.2.2 地下停车场俯仰角变化曲线

同时输出俯仰角以及其对应观测方差的曲线如图4.2.3所示，可以看出除了上述特定波型外，曲线其他地方的波动基本都在方差范围以内，换言之，有很大可能性是由噪声引起的，因此，将其用于车体姿态的补偿可以没有太大意义。

![image-3](https://sunqinxuan.github.io/images/projects-2021-10-13-img6.png)

图4.2.3 地下停车场俯仰角及其方差变化曲线

综上，组合导航系统给出的姿态估计结果，只能用于补偿能带来明显倾斜感的车体姿态变化，而对于平常路面颠簸、经过减速带以及车辆加减速所带来的车体姿态变化，则无法通过组合导航系统给出足够准确的估计。

## 5.运行结果

### 5.1 场景一：地下停车场

<iframe width="1077" height="1076" src="https://www.youtube.com/embed/XHa4P9Y-m7I" title="vokoscreenNG 2024 02 06 17 09 04" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 5.2 场景二：开放道路

<iframe width="1077" height="1076" src="https://www.youtube.com/embed/6cUQkdM8izw" title="vokoscreenNG 2024 02 06 17 23 13" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## 6.相关链接

代码：
- [avm](https://github.com/sunqinxuan/avm)